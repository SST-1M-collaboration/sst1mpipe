{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# %matplotlib inline\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from regions import CircleSkyRegion\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gammapy.analysis import Analysis, AnalysisConfig\n",
    "from gammapy.datasets import MapDatasetOnOff, Datasets\n",
    "from gammapy.estimators import ExcessMapEstimator\n",
    "from gammapy.makers import RingBackgroundMaker\n",
    "\n",
    "from gammapy.data import DataStore\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.datasets import MapDataset\n",
    "from gammapy.makers import MapDatasetMaker, SafeMaskMaker\n",
    "\n",
    "from gammapy.stats import WStatCountsStatistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is directory with IRFs which were used to produce DL3 files\n",
    "irf_dir = \".../IRFs/\"\n",
    "\n",
    "# This is directory containing hdu-index.fits.gz and obs-index.fits.gz. These can be either for one particular \n",
    "# night (as authomaticaly produced in Daily analysis), or for any other time interval. One can use \n",
    "# https://github.com/SST-1M-collaboration/sst1mpipe/blob/main/sst1mpipe/scripts/create_hdu_indexes.py\n",
    "# script to produce joint HDU indexes for some bunch of data to be analyzed.\n",
    "datastore = \"\"\n",
    "\n",
    "# Here you should specify some coordinates where you expect to see something interesting.\n",
    "# Either this way:\n",
    "target_position = SkyCoord.from_name(\"source name\")\n",
    "\n",
    "# Or this way:\n",
    "# source_pos = SkyCoord(10., -25, frame=\"icrs\", unit=\"deg\")\n",
    "# See https://docs.astropy.org/en/stable/api/astropy.coordinates.SkyCoord.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CALDB'] = irf_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datastore\n",
    "data_store = DataStore.from_dir(datastore)\n",
    "data_store.obs_table.sort('TSTART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove some obsids (i.e. wobbles) we do not like\n",
    "# These particular ones are just examples\n",
    "bad_obsids = np.array([202309140409, 202309170461, 202310110480])\n",
    "obsid_mask = [obsid not in list(bad_obsids.astype(int)) for obsid in data_store.obs_table[\"OBS_ID\"]]\n",
    "good_obs_list = data_store.obs_table[obsid_mask]['OBS_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store.obs_table[obsid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = data_store.get_observations(good_obs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theta2 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is how you can plot theta2 plot directly from the final DL3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2_axis = MapAxis.from_bounds(0, 0.5, nbin=30, interp=\"lin\", unit=\"deg2\")\n",
    "norm_theta = [0.5, 0.7] * u.deg\n",
    "n_off = 5\n",
    "theta_cut = 0.2 * u.deg\n",
    "\n",
    "theta2_off = np.zeros([len(theta2_axis.edges)-1, n_off])\n",
    "off_radec = []\n",
    "counts_all_on = []\n",
    "counts_all_all_off=[]\n",
    "\n",
    "sum_norm_on = 0\n",
    "sum_norm_off = 0\n",
    "N_on = 0\n",
    "N_off = 0\n",
    "t_elapsed = 0\n",
    "rate_off_all_all = []\n",
    "n_off_all_all = []\n",
    "\n",
    "for observation in observations:\n",
    "    \n",
    "    mask = data_store.obs_table['OBS_ID'] == observation.obs_id\n",
    "    t_elapsed += data_store.obs_table[mask]['LIVETIME']\n",
    "\n",
    "    # ON counts\n",
    "    separation = source_pos.separation(observation.events.radec)\n",
    "    \n",
    "    N_on += sum(separation < theta_cut)\n",
    "    \n",
    "    counts_on, _ = np.histogram(separation ** 2, bins = theta2_axis.edges)\n",
    "    counts_all_on.append(counts_on)\n",
    "    \n",
    "    norm_on = (separation > norm_theta[0]) & (separation < norm_theta[1])\n",
    "    sum_norm_on += sum(norm_on)\n",
    "\n",
    "    # OFF counts\n",
    "    pos_angle = observation.pointing_radec.position_angle(source_pos)\n",
    "    sep_angle = observation.pointing_radec.separation(source_pos)\n",
    "\n",
    "    # Calculate the OFF counts from the wobble positions (OFF regions) provided\n",
    "    rotation_step = 360 / (n_off + 1)\n",
    "    rotations_off = np.arange(0, 359, rotation_step) * u.deg\n",
    "    rotations_off = rotations_off[rotations_off.to_value(\"deg\") != 0]\n",
    "    rotations_off = pos_angle + rotations_off\n",
    "    \n",
    "    #sum_norm_off = 0\n",
    "    counts_all_off = []\n",
    "    for i_off, rotation in enumerate(rotations_off, start=0):\n",
    "        position_off = observation.pointing_radec.directional_offset_by(rotation, sep_angle)\n",
    "\n",
    "        separation_off = position_off.separation(observation.events.radec)\n",
    "        \n",
    "        N_off += sum(separation_off < theta_cut)\n",
    "        \n",
    "        counts_off_wob, _ = np.histogram(separation_off ** 2, bins = theta2_axis.edges)\n",
    "        \n",
    "        norm_off = (separation_off > norm_theta[0]) & (separation_off < norm_theta[1])\n",
    "        sum_norm_off += sum(norm_off)\n",
    "\n",
    "        counts_all_off.append(counts_off_wob)\n",
    "\n",
    "    #alpha = sum_norm_on/sum_norm_off\n",
    "    counts_all_all_off.append(np.sum(np.array(counts_all_off), axis=0))\n",
    "\n",
    "alpha = sum_norm_on/sum_norm_off\n",
    "\n",
    "stat = WStatCountsStatistic(n_on=N_on, n_off=N_off, alpha=alpha)\n",
    "significance_lima = stat.sqrt_ts\n",
    "N_excess = N_on - alpha*N_off\n",
    "\n",
    "counts_on=np.sum(counts_all_on, axis=0)\n",
    "counts_off=np.sum(np.array(counts_all_all_off), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "ax.errorbar(theta2_axis.center, counts_on, yerr=np.sqrt(counts_on), fmt='o', ms=10)\n",
    "ax.errorbar(theta2_axis.center, alpha*counts_off, yerr=alpha*np.sqrt(counts_off), fmt='o', ms=10)\n",
    "ax.set_xlabel(\"$\\\\theta^{2} [deg^{2}]$\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.grid(ls='dashed')\n",
    "ax.axvline(theta_cut.to_value()**2, color='black',ls='--',alpha=0.75)\n",
    "ax.set_xlim(theta2_axis.bounds[0].value, theta2_axis.bounds[1].value)\n",
    "\n",
    "textstr = r'N$_{{\\rm on}}$ = {:.0f} '\\\n",
    "            f'\\n'\\\n",
    "            r'N$_{{\\rm off}}$ = {:.0f} '\\\n",
    "            f'\\n'\\\n",
    "            r'N$_{{\\rm excess}}$ = {:.0f} '\\\n",
    "            f'\\n'\\\n",
    "            r'n$_{{\\rm off \\, regions}}$ = {:.0f} '\\\n",
    "            f'\\n'\\\n",
    "            r'Time = {:.1f}'\\\n",
    "            f'\\n'\\\n",
    "            r'LiMa Significance = {:.1f} $\\sigma$ '.format(N_on,\n",
    "                                                      N_off,\n",
    "                                                      N_excess,\n",
    "                                                      n_off,\n",
    "                                                      t_elapsed.to(u.h)[0],\n",
    "                                                      significance_lima)\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.95)\n",
    "txt = ax.text(0.50, 0.96, textstr, transform=ax.transAxes, fontsize=15,\n",
    "            verticalalignment='top', bbox=props)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skymaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This settings follows the gammapy examples\n",
    "\n",
    "config = AnalysisConfig()\n",
    "# Select observations - 5 degrees from the source position (in case your indexes indexing all data collected by the telescope for example)\n",
    "config.observations.datastore = datastore\n",
    "config.observations.obs_cone = {\n",
    "    \"frame\": \"icrs\",\n",
    "    \"lon\": source_pos.ra,\n",
    "    \"lat\": source_pos.dec,\n",
    "    \"radius\": 5 * u.deg,\n",
    "}\n",
    "\n",
    "config.datasets.type = \"3d\"\n",
    "config.datasets.geom.wcs.skydir = {\n",
    "    \"lon\": source_pos.ra,\n",
    "    \"lat\": source_pos.dec,\n",
    "    \"frame\": \"icrs\",\n",
    "}  \n",
    "config.datasets.geom.wcs.width = {\"width\": \"5 deg\", \"height\": \"5 deg\"}\n",
    "config.datasets.geom.wcs.binsize = \"0.02 deg\"\n",
    "\n",
    "# Cutout size (for the run-wise event selection)\n",
    "config.datasets.geom.selection.offset_max = 5 * u.deg\n",
    "\n",
    "# We now fix the energy axis for the counts map - (the reconstructed energy binning)\n",
    "config.datasets.geom.axes.energy.min = \"1 TeV\"\n",
    "config.datasets.geom.axes.energy.max = \"100 TeV\"\n",
    "config.datasets.geom.axes.energy.nbins = 20\n",
    "\n",
    "# We need to extract the ring for each observation separately, hence, no stacking at this stage\n",
    "config.datasets.stack = False\n",
    "\n",
    "# safe masks\n",
    "config.datasets.safe_mask.methods = [\"aeff-max\", \"edisp-bias\"]\n",
    "config.datasets.safe_mask.parameters = {\"aeff_percent\": 1, \"bias_percent\": 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.observations.obs_ids = list(np.array(good_obs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = Analysis(config)\n",
    "\n",
    "# for this specific case,w e do not need fine bins in true energy\n",
    "analysis.config.datasets.geom.axes.energy_true = (\n",
    "    analysis.config.datasets.geom.axes.energy\n",
    ")\n",
    "\n",
    "# `First get the required observations\n",
    "analysis.get_observations()\n",
    "\n",
    "print(analysis.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the geom that we use\n",
    "geom = analysis.datasets[0].counts.geom\n",
    "energy_axis = analysis.datasets[0].counts.geom.axes[\"energy\"]\n",
    "geom_image = geom.to_image().to_cube([energy_axis.squash()])\n",
    "\n",
    "# Make the exclusion mask\n",
    "region_source = CircleSkyRegion(center=source_pos, radius=0.2 * u.deg)\n",
    "exclusion_mask = ~geom_image.region_mask([region_source])\n",
    "\n",
    "# Or you can mask even more regions to prevent biased bkg estimations, if you know there is another gamma-ray source nearby\n",
    "#source_pos2 = SkyCoord(ra=49.94999*u.degree, dec=41.511666*u.degree, frame='icrs')\n",
    "#region_source2 = CircleSkyRegion(center=source_pos2, radius=0.2 * u.deg)\n",
    "#exclusion_mask = ~geom_image.region_mask([region_source, region_source2])\n",
    "\n",
    "ax = exclusion_mask.sum_over_axes().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For skymaps we estimate background from a ring around each position withing the FoV\n",
    "ring_maker = RingBackgroundMaker(\n",
    "    r_in=\"0.6 deg\", width=\"0.2 deg\", exclusion_mask=exclusion_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_axis_true = analysis.datasets[0].exposure.geom.axes[\"energy_true\"]\n",
    "stacked_on_off = MapDatasetOnOff.create(\n",
    "    geom=geom_image, energy_axis_true=energy_axis_true, name=\"stacked\"\n",
    ")\n",
    "\n",
    "for dataset in analysis.datasets:\n",
    "    # Ring extracting makes sense only for 2D analysis\n",
    "    dataset_on_off = ring_maker.run(dataset.to_image())\n",
    "    stacked_on_off.stack(dataset_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stacked_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a convolution radius of 0.1 degrees\n",
    "estimator = ExcessMapEstimator(0.1 * u.deg, selection_optional=[])\n",
    "\n",
    "lima_maps = estimator.run(stacked_on_off)\n",
    "\n",
    "significance_map = lima_maps[\"sqrt_ts\"].copy()\n",
    "excess_map = lima_maps[\"npred_excess\"].copy()\n",
    "\n",
    "# We can plot the excess and significance maps\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    figsize=(11, 5), subplot_kw={\"projection\": lima_maps.geom.wcs}, ncols=2\n",
    ")\n",
    "\n",
    "ax1.set_title(\"Significance map\")\n",
    "significance_map.plot(ax=ax1, add_cbar=True, )\n",
    "\n",
    "ax2.set_title(\"Excess map\")\n",
    "excess_map.plot(ax=ax2, add_cbar=True)\n",
    "\n",
    "\n",
    "ax1.plot(significance_map.geom.center_pix[0],\n",
    "         significance_map.geom.center_pix[1],\n",
    "         'x',\n",
    "         color='black',\n",
    "         label=\"Estimated source position\",\n",
    "        )\n",
    "\n",
    "\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.4)\n",
    "ax2.grid(alpha=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution of significance for signal region and everything except the exclusion mask, i.e. the background\n",
    "\n",
    "significance_map = lima_maps[\"sqrt_ts\"].copy()\n",
    "excess_map = lima_maps[\"npred_excess\"].copy()\n",
    "\n",
    "significance_map_off = significance_map * exclusion_mask\n",
    "significance_all = significance_map.data[np.isfinite(significance_map.data)]\n",
    "significance_off = significance_map_off.data[np.isfinite(significance_map_off.data)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    significance_all,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=\"red\",\n",
    "    label=\"all bins\",\n",
    "    bins=51,\n",
    "    range=[min(significance_all), max(significance_all)]\n",
    ")\n",
    "\n",
    "ax.hist(\n",
    "    significance_off,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=\"blue\",\n",
    "    label=\"off bins\",\n",
    "    bins=51,\n",
    "    range=[min(significance_all), max(significance_all)]\n",
    ")\n",
    "\n",
    "# Now, fit the off distribution with a Gaussian\n",
    "mu, std = norm.fit(significance_off)\n",
    "x = np.linspace(-8, 8, 50)\n",
    "p = norm.pdf(x, mu, std)\n",
    "ax.plot(x, p, lw=2, color=\"black\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Significance\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylim(1e-5, 1)\n",
    "xmin, xmax = np.min(significance_all), np.max(significance_all)\n",
    "ax.set_xlim(xmin, xmax)\n",
    "\n",
    "print(f\"Fit results: mu = {mu:.2f}, std = {std:.2f}\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
