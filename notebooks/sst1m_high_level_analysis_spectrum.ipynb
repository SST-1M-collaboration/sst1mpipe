{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from regions import CircleSkyRegion\n",
    "import astropy.units as u\n",
    "import os\n",
    "from pathlib import Path\n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gammapy.data import DataStore\n",
    "\n",
    "from gammapy.datasets import (\n",
    "    Datasets,\n",
    "    SpectrumDataset,\n",
    ")\n",
    "\n",
    "from gammapy.estimators import FluxPointsEstimator\n",
    "from gammapy.makers import (\n",
    "    ReflectedRegionsBackgroundMaker,\n",
    "    SafeMaskMaker,\n",
    "    SpectrumDatasetMaker,\n",
    ")\n",
    "\n",
    "from gammapy.maps import MapAxis, RegionGeom, WcsGeom\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    LogParabolaSpectralModel,\n",
    "    PowerLawSpectralModel,\n",
    "    SkyModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is directory with IRFs which were used to produce DL3 files\n",
    "irf_dir = \".../IRFs/\"\n",
    "\n",
    "# This is directory containing hdu-index.fits.gz and obs-index.fits.gz. These can be either for one particular \n",
    "# night (as authomaticaly produced in Daily analysis), or for any other time interval. One can use \n",
    "# https://github.com/SST-1M-collaboration/sst1mpipe/blob/main/sst1mpipe/scripts/create_hdu_indexes.py\n",
    "# script to produce joint HDU indexes for some bunch of data to be analyzed.\n",
    "datastore = \"\"\n",
    "\n",
    "# Here you should specify some coordinates where you expect to see something interesting.\n",
    "# Either this way:\n",
    "target_position = SkyCoord.from_name(\"source name\")\n",
    "\n",
    "# Or this way:\n",
    "# source_pos = SkyCoord(10., -25, frame=\"icrs\", unit=\"deg\")\n",
    "# See https://docs.astropy.org/en/stable/api/astropy.coordinates.SkyCoord.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CALDB'] = irf_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the target and on region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_region_radius = Angle(\"0.2 deg\")\n",
    "on_region = CircleSkyRegion(center=target_position, radius=on_region_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load datastore\n",
    "data_store = DataStore.from_dir(datastore)\n",
    "data_store.obs_table.sort('TSTART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove some obsids (i.e. wobbles) we do not like\n",
    "# These particular ones are just examples\n",
    "bad_obsids = np.array([202309140409, 202309170461, 202310110480])\n",
    "obsid_mask = [obsid not in list(bad_obsids.astype(int)) for obsid in data_store.obs_table[\"OBS_ID\"]]\n",
    "good_obs_list = data_store.obs_table[obsid_mask]['OBS_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store.obs_table[obsid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_obs_table = data_store.obs_table[obsid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = data_store.get_observations(good_obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional : we define exclusion region around the target to avoid contamination in the OFF regions\n",
    "\n",
    "exclusion_region = CircleSkyRegion(\n",
    "    center=target_position,\n",
    "    radius=0.25 * u.deg,\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    npix=(150, 150), binsz=0.05, skydir=target_position, proj=\"TAN\", frame=\"icrs\"\n",
    ")\n",
    "\n",
    "exclusion_mask = ~geom.region_mask([exclusion_region])\n",
    "exclusion_mask.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reco energy axis should be the same also for the flux points\n",
    "emin=1\n",
    "emax=100\n",
    "nbin = 12\n",
    "energy_axis = MapAxis.from_energy_bounds(\n",
    "    emin, emax, nbin=nbin, per_decade=True, unit=\"TeV\", name=\"energy\"\n",
    ")\n",
    "\n",
    "energy_axis_true = MapAxis.from_energy_bounds(\n",
    "    0.2, 150, nbin=41, per_decade=True, unit=\"TeV\", name=\"energy_true\"\n",
    ")\n",
    "\n",
    "geom = RegionGeom.create(region=on_region, axes=[energy_axis])\n",
    "dataset_empty = SpectrumDataset.create(geom=geom, energy_axis_true=energy_axis_true)\n",
    "\n",
    "dataset_maker = SpectrumDatasetMaker(\n",
    "    containment_correction=True, selection=[\"counts\", \"exposure\", \"edisp\"]\n",
    ")\n",
    "\n",
    "bkg_maker = ReflectedRegionsBackgroundMaker(exclusion_mask=exclusion_mask)\n",
    "safe_mask_masker = SafeMaskMaker(methods=[\"aeff-max\", \"edisp-bias\"], aeff_percent=1, bias_percent=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked_datasets = Datasets()\n",
    "\n",
    "## loop on the observation : \n",
    "for obs_id, observation in zip(selected_obs_table[\"OBS_ID\"], observations):\n",
    "    print(\"processing obs {}\".format(obs_id))\n",
    "    dataset = dataset_maker.run(dataset_empty.copy(name=str(obs_id)), observation)\n",
    "    dataset_on_off = bkg_maker.run(dataset, observation)\n",
    "    dataset_on_off = safe_mask_masker.run(dataset_on_off, observation)\n",
    "    unstacked_datasets.append(dataset_on_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some cumulative stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_table = unstacked_datasets.info_table(cumulative=True)\n",
    "info_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_excess, ax_sqrt_ts) = plt.subplots(figsize=(10, 4), ncols=2, nrows=1)\n",
    "ax_excess.plot(\n",
    "    info_table[\"livetime\"].to(\"h\"),\n",
    "    info_table[\"excess\"],\n",
    "    marker=\".\",\n",
    "    ls=\"none\",\n",
    ")\n",
    "\n",
    "ax_excess.set_title(\"Excess\")\n",
    "ax_excess.set_xlabel(\"Livetime [h]\")\n",
    "ax_excess.set_ylabel(\"Excess events\")\n",
    "\n",
    "ax_sqrt_ts.plot(\n",
    "    info_table[\"livetime\"].to(\"h\"),\n",
    "    info_table[\"sqrt_ts\"],\n",
    "    marker=\".\",\n",
    "    ls=\"none\",\n",
    ")\n",
    "\n",
    "ax_sqrt_ts.set_title(\"Sqrt(TS)\")\n",
    "ax_sqrt_ts.set_xlabel(\"Livetime [h]\")\n",
    "ax_sqrt_ts.set_ylabel(\"Sqrt(TS)\")\n",
    "\n",
    "ax_excess.grid()\n",
    "ax_sqrt_ts.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define spectral models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Log parabola model : \n",
    "logp_model = LogParabolaSpectralModel(\n",
    "    amplitude=1e-12 * u.Unit(\"cm-2 s-1 TeV-1\"),\n",
    "    reference = 5. * u.TeV,\n",
    "    )\n",
    "\n",
    "## PL\n",
    "pwl_model = PowerLawSpectralModel(\n",
    "    amplitude=1e-12 * u.Unit(\"cm-2 s-1 TeV-1\"),\n",
    "    index=2,\n",
    "    reference=5. * u.TeV,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit of stacked dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stacked = Datasets(unstacked_datasets).stack_reduce(name='Crab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For likelihood ratio test (see https://github.com/luca-giunti/CTAO-CTAC_Meeting_Bologna_2022/blob/main/1D_analysis.ipynb)\n",
    "\n",
    "# H0 hypothesis - there is only background in the data\n",
    "Wstat_0 = dataset_stacked.stat_sum()\n",
    "# this is -2 logL for H0 hypothesis\n",
    "print(\"-2 logL for H0 hypothesis:\", Wstat_0)\n",
    "# residual with H0 hypothesis, so if there is a source, there should be positive residuals suggesting that we miss something in the model (the source)\n",
    "dataset_stacked.plot_residuals_spectral()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the source model\n",
    "model = SkyModel(spectral_model=pwl_model, name=\"source\")\n",
    "\n",
    "dataset_stacked.models = [model]\n",
    "\n",
    "# run the FIT !\n",
    "fit = Fit()\n",
    "result_stacked = fit.run(datasets=dataset_stacked)\n",
    "\n",
    "model_best_stacked = model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if the fit converged\n",
    "print(result_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model covariance matrix plot\n",
    "model_best_stacked.covariance.plot_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result_stacked.models.to_parameters_table())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit quality and model residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_spectrum, ax_residuals = dataset_stacked.plot_fit()\n",
    "dataset_stacked.plot_masks(ax=ax_spectrum)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "# For H1 hypothesis - there is a source with power-law spectrum\n",
    "Wstat_1 = result_stacked.total_stat\n",
    "print(\"-2 logL for H1 hypothesis:\", Wstat_1)\n",
    "\n",
    "# dof for PL is 2 (sp index and normalization)\n",
    "dof = 2\n",
    "# this number is significance of detection\n",
    "print(\"delta TS of detection: \", (Wstat_0-Wstat_1), \"p-value: \", chi2.sf((Wstat_0-Wstat_1), dof))\n",
    "\n",
    "# It can be then converted to sigma for PL model with 2 deg of freedom:\n",
    "\n",
    "# TS -> sigma prescription is from gammapy documentation\n",
    "# https://docs.gammapy.org/0.18.2/stats/index.html\n",
    "\n",
    "from scipy.stats import norm\n",
    "p_value = chi2.sf((Wstat_0-Wstat_1), dof)\n",
    "sigma = norm.isf(p_value / 2)\n",
    "print(\"significance in units of sigma:\", sigma)\n",
    "# test that we get the same p_value from this sigma:\n",
    "p_value = 2 * (1 - norm.cdf(sigma))\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Flux Point\n",
    "To round up our analysis we can compute flux points by fitting the norm of the global model in energy bands. We can utilise the resample_energy_edges for defining the energy bins in which the minimum number of sqrt_ts is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_edges = np.geomspace(emin, emax, nbin+1) * u.TeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpe = FluxPointsEstimator(\n",
    "    energy_edges=energy_edges, source=\"source\", selection_optional=\"all\"\n",
    ")\n",
    "flux_points = fpe.run(datasets=dataset_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(flux_points.to_table(sed_type=\"dnde\", formatted=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.yaxis.set_units(u.TeV/(u.cm**2 * u.s))\n",
    "flux_points.plot(ax=ax, sed_type=\"e2dnde\", color=\"darkorange\")\n",
    "flux_points.plot_ts_profiles(ax=ax, sed_type=\"e2dnde\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
